{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf92fb8-5c33-4c99-a2f4-ce3a8af65118",
   "metadata": {},
   "source": [
    "# Model Distillation - Additive Cyclic Boosted Tree\n",
    "\n",
    "This notebook focuses on using Tree-based model distillation. Focuses on using teacher, neural network and student, Cyclic gradient boosting decision tree, to create a interpretable model. The methodology is based on Tan, S., Caruana, R., Hooker, G., Koch, P., and Gordo, A. (2018). \n",
    "\n",
    "Notes on paper :\n",
    "\n",
    "https://www.notion.so/Model-Distillation-Tree-Based-LEARNING-GLOBAL-ADDITIVE-EXPLANATIONS-FOR-NEURAL-NETS-USING-MODEL-10ec2f4dbaa0800eb2ffeb76d1b8f744?pvs=4\n",
    "\n",
    "Outline of Method:\n",
    "\n",
    "1. Initialize Teacher Model : Create a FNN using Relu Functions, output is logits\n",
    "2. Initialize Student Model : Initialize a decision tree model, with a learning rate and number of cycles\n",
    "3. Optimise Decision tree: Using bagging / cyclic gradient boosting traing new $ h_m $: $ r_m = F(x) - \\hat{F}_{m-1}(x) $\n",
    "   \n",
    "        - Cycle through feature subsets: Train each tree on different feature groups sequentially.\n",
    "        - Cycle through loss functions: Use different loss functions (e.g., Mean Squared Error, KL Divergence) in alternating iterations.\n",
    "\n",
    "4. Combine the Models: At the end of the iterations, the final student model will be an additive combination of all the trees trained during the process. Each tree corrects the residuals from the previous models.\n",
    "5. using gSHAP to visualise feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5835a5e5-3c98-42ba-beb0-35027a293c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch \n",
    "    from torch.nn import Module\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import numpy as np \n",
    "    import scipy \n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "except: \n",
    "    print(f\"Import not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff36ee5-8da0-4184-819c-7d767fa4655d",
   "metadata": {},
   "source": [
    "# Creating DataLoader and Dataset Class to load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0d01baac-4741-497e-adca-c1cac4a29f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to get data....\n",
      "Data is laoded and in df....\n",
      "Trying to label data...\n",
      "Dataframe is now labelled...\n",
      "Converting features and labels from dataframe to tensors..\n",
      "Completed converting features and labels to tensors...\n",
      "Shape of X : torch.Size([2964, 124])\n",
      "Shape of y : torch.Size([2964])\n",
      "Converting into training and testing split...\n",
      "Finished converting into training and testing split...\n",
      "Length X_train: 2074 | X_test : 890 | y_train : 2074 | y_test : 890 \n"
     ]
    }
   ],
   "source": [
    "# Get data into DataFrame \n",
    "try: \n",
    "    print(\"Trying to get data....\")\n",
    "    DATA_PATH = '../../data/01_encoded_no_transformations/01_encoded_no_transformations.csv'\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Data is laoded and in df....\")\n",
    "except LookupError as e:\n",
    "    print(f\"Could find {e}\")\n",
    "\n",
    "# Create Labels \n",
    "try:\n",
    "    print(\"Trying to label data...\")\n",
    "    X = df.drop(columns=['fraud_reported'])\n",
    "    y = df['fraud_reported']\n",
    "    print(\"Dataframe is now labelled...\")\n",
    "    \n",
    "    # Convert to Tensors\n",
    "    print(\"Converting features and labels from dataframe to tensors..\")\n",
    "    X = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "    y = torch.from_numpy(y.to_numpy())\n",
    "    print(\"Completed converting features and labels to tensors...\")\n",
    "    print(f\"Shape of X : {X.shape}\")\n",
    "    print(f\"Shape of y : {y.shape}\") \n",
    "except Exception as e:\n",
    "    print(f\"Failed {e}\")\n",
    "    \n",
    "# Splitting Data into train, test \n",
    "try:\n",
    "    print(\"Converting into training and testing split...\")\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42\n",
    "    )\n",
    "    print(\"Finished converting into training and testing split...\")\n",
    "    print(f\"Length X_train: {len(X_train)} | X_test : {len(X_test)} | y_train : {len(y_train)} | y_test : {len(y_test)} \")\n",
    "except Exception as e:\n",
    "    print(f\"Failed {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71203b81-73a1-4a5c-92b0-5e05be746971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Dataset class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe8ba8-6861-4c9e-bdb5-550da0f6fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac149e7c-b8d8-4038-91a3-222786bb2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
