{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cf92fb8-5c33-4c99-a2f4-ce3a8af65118",
   "metadata": {},
   "source": [
    "# Model Distillation - Additive Cyclic Boosted Tree\n",
    "\n",
    "This notebook focuses on using Tree-based model distillation. Focuses on using teacher, neural network and student, Cyclic gradient boosting decision tree, to create a interpretable model. The methodology is based on Tan, S., Caruana, R., Hooker, G., Koch, P., and Gordo, A. (2018). \n",
    "\n",
    "Notes on paper :\n",
    "\n",
    "https://www.notion.so/Model-Distillation-Tree-Based-LEARNING-GLOBAL-ADDITIVE-EXPLANATIONS-FOR-NEURAL-NETS-USING-MODEL-10ec2f4dbaa0800eb2ffeb76d1b8f744?pvs=4\n",
    "\n",
    "Outline of Method:\n",
    "\n",
    "1. Initialize Teacher Model : Create a FNN using Relu Functions, output is logits\n",
    "2. Initialize Student Model : Initialize a decision tree model, with a learning rate and number of cycles\n",
    "3. Optimise Decision tree: Using bagging / cyclic gradient boosting traing new $ h_m $: $ r_m = F(x) - \\hat{F}_{m-1}(x) $\n",
    "   \n",
    "        - Cycle through feature subsets: Train each tree on different feature groups sequentially.\n",
    "        - Cycle through loss functions: Use different loss functions (e.g., Mean Squared Error, KL Divergence) in alternating iterations.\n",
    "\n",
    "4. Combine the Models: At the end of the iterations, the final student model will be an additive combination of all the trees trained during the process. Each tree corrects the residuals from the previous models.\n",
    "5. using gSHAP to visualise feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff36ee5-8da0-4184-819c-7d767fa4655d",
   "metadata": {},
   "source": [
    "# Creating DataLoader and Dataset Class to load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5835a5e5-3c98-42ba-beb0-35027a293c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import torch \n",
    "    from torch.nn import Module\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    import numpy as np \n",
    "    import scipy \n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    from pathlib import Path\n",
    "except: \n",
    "    print(f\"Import not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0d01baac-4741-497e-adca-c1cac4a29f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to get data....\n",
      "Data is laoded and in df....\n",
      "Trying to label data...\n",
      "Dataframe is now labelled...\n",
      "Converting features and labels from dataframe to tensors..\n",
      "Completed converting features and labels to tensors...\n",
      "Shape of X : torch.Size([2964, 124])\n",
      "Shape of y : torch.Size([2964])\n",
      "Converting into training and testing split...\n",
      "Finished converting into training and testing split...\n",
      "Length X_train: 2371 | X_test : 593 | y_train : 2371 | y_test : 593 \n",
      "All data loaded\n"
     ]
    }
   ],
   "source": [
    "# Get data into DataFrame \n",
    "try: \n",
    "    print(\"Trying to get data....\")\n",
    "    DATA_PATH = '../../data/01_encoded_no_transformations/01_encoded_no_transformations.csv'\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(\"Data is laoded and in df....\")\n",
    "except LookupError as e:\n",
    "    print(f\"Couldn't find {e}\")\n",
    "\n",
    "# Create Labels \n",
    "try:\n",
    "    print(\"Trying to label data...\")\n",
    "    X = df.drop(columns=['fraud_reported'])\n",
    "    y = df['fraud_reported']\n",
    "    print(\"Dataframe is now labelled...\")\n",
    "    \n",
    "    # Convert to Tensors\n",
    "    print(\"Converting features and labels from dataframe to tensors..\")\n",
    "    X = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "    y = torch.from_numpy(y.to_numpy())\n",
    "    print(\"Completed converting features and labels to tensors...\")\n",
    "    print(f\"Shape of X : {X.shape}\")\n",
    "    print(f\"Shape of y : {y.shape}\") \n",
    "except Exception as e:\n",
    "    print(f\"Failed {e}\")\n",
    "    \n",
    "# Splitting Data into train, test \n",
    "try:\n",
    "    print(\"Converting into training and testing split...\")\n",
    "    import sklearn\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    print(\"Finished converting into training and testing split...\")\n",
    "    print(f\"Length X_train: {len(X_train)} | X_test : {len(X_test)} | y_train : {len(y_train)} | y_test : {len(y_test)} \")\n",
    "    print(\"All data loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "71203b81-73a1-4a5c-92b0-5e05be746971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Custom Dataset...\n",
      "Created Custom Dataset...\n",
      "Testing len function...\n",
      "Length of features: 2371 and labels: 2371\n",
      "Train dataset length: 2371\n",
      "Length of features: 593 and labels: 593\n",
      "Test dataset length: 593\n",
      "Finished Testing Length...\n",
      "Testing get function for train ...\n",
      "Features shape: torch.Size([124])\n",
      "Label shape: torch.Size([])\n",
      "0.0\n",
      "Testing get function finished train...\n",
      "Testing get function for test ...\n",
      "Features shape: torch.Size([124])\n",
      "Label shape: torch.Size([])\n",
      "Testing get function Finished for test ...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import Module\n",
    "\n",
    "class CustomDataset(Module):\n",
    "    def __init__(self, features: torch.Tensor, labels: torch.Tensor):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        self.labels = labels \n",
    "\n",
    "    # Get length of data\n",
    "    def __len__(self):\n",
    "        features_len = len(self.features)\n",
    "        label_len = len(self.labels)\n",
    "        print(f\"Length of features: {features_len} and labels: {label_len}\")\n",
    "        return features_len  # Ensure to return the length\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        try:\n",
    "            feature = self.features[idx]\n",
    "            label = self.labels[idx]\n",
    "            print(f\"Features shape: {feature.shape}\")\n",
    "            print(f\"Label shape: {label.shape}\")\n",
    "            return feature, label\n",
    "        except IndexError as e:\n",
    "            print(f\"This index is not in features: {e}\")\n",
    "            raise\n",
    "\n",
    "# Example usage:\n",
    "try:\n",
    "    print(\"Creating Custom Dataset...\")\n",
    "    train_dataset = CustomDataset(features=X_train, labels=y_train)\n",
    "    test_dataset = CustomDataset(features=X_test, labels=y_test)\n",
    "    print(\"Created Custom Dataset...\")\n",
    "\n",
    "    print(\"Testing len function...\")\n",
    "    print(f\"Train dataset length: {len(train_dataset)}\")\n",
    "    print(f\"Test dataset length: {len(test_dataset)}\")\n",
    "    print(\"Finished Testing Length...\")\n",
    "\n",
    "    print(\"Testing get function for train ...\")\n",
    "    train_index_0_feature, train_index_0_label = train_dataset[0]  \n",
    "    print(\"Testing get function finished train...\")\n",
    "\n",
    "    print(\"Testing get function for test ...\")\n",
    "    test_index_0_feature, test_index_0_label = test_dataset[0] \n",
    "    print(\"Testing get function Finished for test ...\")   \n",
    "except Exception as e:\n",
    "    print(f\"Error occurred in using CustomDataset class: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2213e03b-50a8-455d-8f29-99d0c84f3b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting DataLoader for Test dataset\n",
      "Length of features: 593 and labels: 593\n",
      "Length of features: 593 and labels: 593\n",
      "Finished DataLoader for Test dataset\n",
      "Starting DataLoader for Training dataset\n",
      "Length of features: 2371 and labels: 2371\n",
      "Length of features: 2371 and labels: 2371\n",
      "Finished DataLoader for Training dataset\n"
     ]
    }
   ],
   "source": [
    "# Create DataLoader\n",
    "try:\n",
    "    print(f\"Starting DataLoader for Test dataset\")\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "    print(f\"Finished DataLoader for Test dataset\")\n",
    "    print(f\"Starting DataLoader for Training dataset\")\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "    print(f\"Finished DataLoader for Training dataset\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occured in DataLoader as {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45bb1b8-6199-4364-99f5-2dd1dc56bac3",
   "metadata": {},
   "source": [
    "# Load Model Teacher Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f620539-a5c3-46bc-814d-4003a5af9d39",
   "metadata": {},
   "source": [
    "# Create and Bag Student Model - Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8265550-bd32-4a22-9bbe-216d6fe960de",
   "metadata": {},
   "source": [
    "# Use gSHARP to create feature importance graphs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
