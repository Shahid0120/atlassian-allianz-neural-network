{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Shahid0120/atlassian-allianz-neural-network/blob/main/experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN0mLjonQw6p"
   },
   "source": [
    "# Deep Neural Network - with Relu Activation Experiment with Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ReiiOU2eQW1J",
    "outputId": "1429b17e-d0a4-4150-db7e-bb7d1b098da3"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  import numpy as np\n",
    "  import scipy\n",
    "  import matplotlib.pyplot as plt\n",
    "  import pandas as pd\n",
    "  import torch\n",
    "  from torch import nn\n",
    "  from pathlib import Path\n",
    "  from torch.optim.sgd import SGD\n",
    "  #from google.colab import userdata\n",
    "\n",
    "  # Set up repo\n",
    "  #password_github = userdata.get('password-github')\n",
    "\n",
    "  #!git config --global user.name \"Shahid0120\"\n",
    "  #!git config --global user.email \"shahid.hussain0120@gmail.com\"\n",
    "  #!git config --global user.password password_github\n",
    "\n",
    "  #token = userdata.get('github-token')\n",
    "  #username = 'Shahid0120'\n",
    "  #repo='atlassian-allianz-neural-network'\n",
    "\n",
    "  #!git clone https://{token}@github.com/{username}/{repo}\n",
    "\n",
    "except:\n",
    "  print(\"Something didnt import or access not granted\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pG0tmB_nQ5Dl"
   },
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "id": "RKc0bWQ4Q7FE",
    "outputId": "d6395092-b896-415c-d708-912182fb1d2a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>capital-gains</th>\n",
       "      <th>incident_severity</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>number_of_vehicles_involved</th>\n",
       "      <th>bodily_injuries</th>\n",
       "      <th>...</th>\n",
       "      <th>auto_model_Pathfinder</th>\n",
       "      <th>auto_model_RAM</th>\n",
       "      <th>auto_model_RSX</th>\n",
       "      <th>auto_model_Silverado</th>\n",
       "      <th>auto_model_TL</th>\n",
       "      <th>auto_model_Tahoe</th>\n",
       "      <th>auto_model_Ultima</th>\n",
       "      <th>auto_model_Wrangler</th>\n",
       "      <th>auto_model_X5</th>\n",
       "      <th>auto_model_X6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556485</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447388</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.671548</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.447797</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.496517</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.539749</td>\n",
       "      <td>0.577778</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.459492</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.299502</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.930962</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.495249</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.496517</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.278243</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.606972</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.349254</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2959</th>\n",
       "      <td>0.135983</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343786</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2960</th>\n",
       "      <td>0.364017</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301668</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961</th>\n",
       "      <td>0.014644</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.510469</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2962</th>\n",
       "      <td>0.037657</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252425</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>0.083682</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.349919</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2964 rows × 125 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      months_as_customer       age  policy_deductable  policy_annual_premium  \\\n",
       "0               0.556485  0.466667           0.000000               0.447388   \n",
       "1               0.671548  0.555556           0.333333               0.447797   \n",
       "2               0.539749  0.577778           1.000000               0.459492   \n",
       "3               0.930962  0.933333           0.333333               0.495249   \n",
       "4               0.278243  0.222222           1.000000               0.606972   \n",
       "...                  ...       ...                ...                    ...   \n",
       "2959            0.135983  0.155556           0.000000               0.343786   \n",
       "2960            0.364017  0.600000           0.000000               0.301668   \n",
       "2961            0.014644  0.200000           1.000000               0.510469   \n",
       "2962            0.037657  0.488889           0.000000               0.252425   \n",
       "2963            0.083682  0.133333           1.000000               0.349919   \n",
       "\n",
       "      umbrella_limit  capital-gains  incident_severity  \\\n",
       "0           0.545455       0.000000           0.000000   \n",
       "1           0.090909       0.496517           0.666667   \n",
       "2           0.090909       0.299502           0.333333   \n",
       "3           0.090909       0.496517           0.333333   \n",
       "4           0.545455       0.349254           0.333333   \n",
       "...              ...            ...                ...   \n",
       "2959        0.090909       0.000000           0.666667   \n",
       "2960        0.090909       0.000000           0.666667   \n",
       "2961        0.090909       0.000000           0.666667   \n",
       "2962        0.090909       0.000000           0.333333   \n",
       "2963        0.090909       0.000000           0.666667   \n",
       "\n",
       "      incident_hour_of_the_day  number_of_vehicles_involved  bodily_injuries  \\\n",
       "0                     0.217391                     0.000000              0.0   \n",
       "1                     0.869565                     0.666667              0.0   \n",
       "2                     1.000000                     0.000000              1.0   \n",
       "3                     0.130435                     0.000000              0.0   \n",
       "4                     0.304348                     0.666667              0.0   \n",
       "...                        ...                          ...              ...   \n",
       "2959                  0.043478                     0.000000              1.0   \n",
       "2960                  0.130435                     0.666667              0.0   \n",
       "2961                  0.869565                     0.000000              1.0   \n",
       "2962                  0.086957                     0.000000              0.0   \n",
       "2963                  0.434783                     0.666667              1.0   \n",
       "\n",
       "      ...  auto_model_Pathfinder  auto_model_RAM  auto_model_RSX  \\\n",
       "0     ...                    0.0             0.0             0.0   \n",
       "1     ...                    0.0             0.0             0.0   \n",
       "2     ...                    0.0             0.0             0.0   \n",
       "3     ...                    0.0             0.0             0.0   \n",
       "4     ...                    0.0             1.0             0.0   \n",
       "...   ...                    ...             ...             ...   \n",
       "2959  ...                    0.0             0.0             0.0   \n",
       "2960  ...                    0.0             0.0             0.0   \n",
       "2961  ...                    0.0             0.0             0.0   \n",
       "2962  ...                    0.0             0.0             0.0   \n",
       "2963  ...                    0.0             0.0             0.0   \n",
       "\n",
       "      auto_model_Silverado  auto_model_TL  auto_model_Tahoe  \\\n",
       "0                      0.0            0.0               0.0   \n",
       "1                      0.0            0.0               0.0   \n",
       "2                      0.0            0.0               0.0   \n",
       "3                      0.0            0.0               0.0   \n",
       "4                      0.0            0.0               0.0   \n",
       "...                    ...            ...               ...   \n",
       "2959                   0.0            0.0               0.0   \n",
       "2960                   0.0            0.0               0.0   \n",
       "2961                   0.0            0.0               0.0   \n",
       "2962                   0.0            0.0               0.0   \n",
       "2963                   0.0            0.0               0.0   \n",
       "\n",
       "      auto_model_Ultima  auto_model_Wrangler  auto_model_X5  auto_model_X6  \n",
       "0                   0.0                  0.0            0.0            0.0  \n",
       "1                   0.0                  1.0            0.0            0.0  \n",
       "2                   0.0                  0.0            0.0            0.0  \n",
       "3                   0.0                  0.0            0.0            0.0  \n",
       "4                   0.0                  0.0            0.0            0.0  \n",
       "...                 ...                  ...            ...            ...  \n",
       "2959                0.0                  0.0            0.0            0.0  \n",
       "2960                0.0                  0.0            0.0            0.0  \n",
       "2961                0.0                  0.0            0.0            0.0  \n",
       "2962                0.0                  0.0            0.0            0.0  \n",
       "2963                0.0                  0.0            0.0            0.0  \n",
       "\n",
       "[2964 rows x 125 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "#dataPath = './atlassian-allianz-neural-network/data/01_encoded_no_transformations/01_encoded_no_transformations.csv'\n",
    "dataPath = './data/01_encoded_no_transformations/01_encoded_no_transformations.csv'\n",
    "data = pd.read_csv(dataPath)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yi_QUghbRZ6q",
    "outputId": "ad0fe28b-55dd-4fb4-c47c-77eaa9202f85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X : torch.Size([2964, 124])\n",
      "Shape of y : (2964,)\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['fraud_reported'])\n",
    "Y = data['fraud_reported']\n",
    "\n",
    "# Conver into tensor\n",
    "X = torch.from_numpy(X.to_numpy()).type(torch.float)\n",
    "y = torch.from_numpy(Y.to_numpy())\n",
    "\n",
    "print(f\"Shape of X : {X.shape}\")\n",
    "print(f\"Shape of y : {Y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7wAJ7rRBS_dU"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9QoWdqCTTBb3",
    "outputId": "3006f97a-fa47-4459-a493-a2ec5032c989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of X_train : 2371 | X_test : 593 | y_train : 2371 | y_test : 593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=43\n",
    ")\n",
    "\n",
    "print(f\"len of X_train : {len(X_train)} | X_test : {len(X_test)} | y_train : {len(y_train)} | y_test : {len(y_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "nqYu_dFxZ0MN"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "\n",
    "class CustomerDataset(Dataset):\n",
    "    def __init__(self, features: torch.Tensor, labels: torch.Tensor):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return feature and label\n",
    "        feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = CustomerDataset(X_train, y_train)\n",
    "test_dataset = CustomerDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoader instances\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2MsmDrYLSLx"
   },
   "source": [
    "Creating NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CUS5N08aLT-s",
    "outputId": "9dcabb41-ea66-472a-cde1-c3a589a96bb4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModelV4(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=124, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# creating 4 layer RELU\n",
    "class ModelV4(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layers = nn.Sequential(\n",
    "        nn.Linear(in_features=124, out_features=10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=10, out_features=10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=10, out_features=10),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(in_features=10, out_features=10)\n",
    "    )\n",
    "\n",
    "  def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "      return self.layers(x)\n",
    "\n",
    "modelv4 = ModelV4()\n",
    "modelv4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3jvO894eI5aT",
    "outputId": "12c5b533-4105-452f-acb9-d208e250489a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: torchinfo in /opt/anaconda3/lib/python3.12/site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WbE19KG_NISc",
    "outputId": "7eb19e69-df5c-4d11-9db1-6f50ba8462fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ModelV4                                  [32, 10]                  --\n",
       "├─Sequential: 1-1                        [32, 10]                  --\n",
       "│    └─Linear: 2-1                       [32, 10]                  1,250\n",
       "│    └─ReLU: 2-2                         [32, 10]                  --\n",
       "│    └─Linear: 2-3                       [32, 10]                  110\n",
       "│    └─ReLU: 2-4                         [32, 10]                  --\n",
       "│    └─Linear: 2-5                       [32, 10]                  110\n",
       "│    └─ReLU: 2-6                         [32, 10]                  --\n",
       "│    └─Linear: 2-7                       [32, 10]                  110\n",
       "==========================================================================================\n",
       "Total params: 1,580\n",
       "Trainable params: 1,580\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.05\n",
       "==========================================================================================\n",
       "Input size (MB): 0.02\n",
       "Forward/backward pass size (MB): 0.01\n",
       "Params size (MB): 0.01\n",
       "Estimated Total Size (MB): 0.03\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(modelv4, input_size=(32, 124))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuEZ3vgTN-Ze"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DzIj9j5eP7iN",
    "outputId": "662859e8-7124-4e01-888f-6f1fec23068e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "821ll-FkSox8"
   },
   "source": [
    "## Creating training and test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "4-q9k51zSgq-"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# Train step function\n",
    "def train_step(model: torch.nn.Module,\n",
    "               train_dataloader: torch.utils.data.DataLoader,\n",
    "               loss: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer):\n",
    "    model.train()  # Set model to train mode\n",
    "    \n",
    "    train_loss, train_acc = 0, 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "          # Forward pass\n",
    "          y_pred = model(X)\n",
    "        \n",
    "          # Calculate loss\n",
    "          loss_val = loss(y_pred, y)\n",
    "          train_loss += loss_val.item()\n",
    "        \n",
    "          # Optimizer zero grad\n",
    "          optimizer.zero_grad()\n",
    "        \n",
    "          # Backward pass\n",
    "          loss_val.backward()\n",
    "        \n",
    "          # Update weights\n",
    "          optimizer.step()\n",
    "        \n",
    "          # Calculate accuracy\n",
    "          y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
    "          train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
    "        \n",
    "    # Average loss and accuracy per batch\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    \n",
    "    return train_loss, train_acc\n",
    "\n",
    "# Test step function\n",
    "def test_step(model: torch.nn.Module,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss: torch.nn.Module):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            # Forward pass\n",
    "            test_y_logits = model(X)\n",
    "            \n",
    "            # Calculate loss\n",
    "            loss_val = loss(test_y_logits, y)\n",
    "            test_loss += loss_val.item()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            test_pred_labels = test_y_logits.argmax(dim=1)\n",
    "            test_acc += (test_pred_labels == y).sum().item() / len(test_pred_labels)\n",
    "\n",
    "    # Average loss and accuracy per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "    test_acc /= len(test_dataloader)\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "# Main training loop function\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          loss: torch.nn.Module,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          epochs: int):\n",
    "\n",
    "    results = {\n",
    "      \"train_loss\": [],\n",
    "      \"train_acc\": [],\n",
    "      \"test_loss\": [],\n",
    "      \"test_acc\": []\n",
    "    }\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                          train_dataloader=train_dataloader,\n",
    "                                          loss=loss,\n",
    "                                          optimizer=optimizer)\n",
    "        \n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                      test_dataloader=test_dataloader,\n",
    "                                      loss=loss)\n",
    "        \n",
    "        print(f\"Epoch: {epoch+1} | Train Loss: {train_loss:.4f} | Test Loss: {test_loss:.4f} | Train Acc: {train_acc:.4f} | Test Acc: {test_acc:.4f}\")\n",
    "    \n",
    "        # Append training loss for each epoch\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, epoch+1)\n",
    "        writer.add_scalar('Loss/test', test_loss, epoch+1)\n",
    "        writer.add_scalar('Accuracy/train', train_acc, epoch+1)\n",
    "        writer.add_scalar('Accuracy/test', test_acc, epoch+1)\n",
    "        \n",
    "    # Append into results\n",
    "    results[\"train_loss\"].append(train_loss)\n",
    "    results[\"train_acc\"].append(train_acc)\n",
    "    results[\"test_loss\"].append(test_loss)\n",
    "    results[\"test_acc\"].append(test_acc)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_cxkB25Ujhcn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install mlflow and pyngrok (only needed the first time)\n",
    "!pip install mlflow --quiet\n",
    "!pip install pyngrok --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tqdm is installed\n",
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: tqdm in /opt/anaconda3/lib/python3.12/site-packages (4.66.4)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "  Attempting uninstall: tqdm\n",
      "    Found existing installation: tqdm 4.66.4\n",
      "    Uninstalling tqdm-4.66.4:\n",
      "      Successfully uninstalled tqdm-4.66.4\n",
      "Successfully installed tqdm-4.66.5\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import tqdm\n",
    "    print(\"tqdm is installed\")\n",
    "except ImportError:\n",
    "    print(\"tqdm is not installed\")\n",
    "!pip install --upgrade tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "4FNIXErwSsUB",
    "outputId": "36aca7e3-bca8-4af4-ffb9-2a0910d32d0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "API request to endpoint /api/2.0/mlflow/runs/create failed with error code 404 != 200. Response body: '<!DOCTYPE html>\n<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n  <head>\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Semibold-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <meta charset=\"utf-8\">\n    <meta name=\"author\" content=\"ngrok\">\n    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n    <meta name=\"robots\" content=\"noindex, nofollow\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n    <noscript>Tunnel 5f5e-34-168-89-14.ngrok-free.app not found (ERR_NGROK_3200)</noscript>\n    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n  </head>\n  <body class=\"h-full\" id=\"ngrok\">\n    <div id=\"root\" data-payload=\"eyJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiIzMjAwIiwibWVzc2FnZSI6IlR1bm5lbCA1ZjVlLTM0LTE2OC04OS0xNC5uZ3Jvay1mcmVlLmFwcCBub3QgZm91bmQiLCJ0aXRsZSI6Ik5vdCBGb3VuZCJ9\"></div>\n  </body>\n</html>\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-d06f6e1c82f7>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mmlflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     model_4_results = train(model=modelv4,\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/tracking/fluent.py\u001b[0m in \u001b[0;36mstart_run\u001b[0;34m(run_id, experiment_id, run_name, nested, parent_run_id, tags, description, log_system_metrics)\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0mresolved_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_specified_tags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         active_run_obj = client.create_run(\n\u001b[0m\u001b[1;32m    419\u001b[0m             \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexp_id_for_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresolved_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/tracking/client.py\u001b[0m in \u001b[0;36mcreate_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRUNNING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \"\"\"\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tracking_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_upload_trace_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_info\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraceInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTraceData\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/tracking/_tracking_service/client.py\u001b[0m in \u001b[0;36mcreate_run\u001b[0;34m(self, experiment_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0muser_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMLFLOW_USER\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unknown\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         return self.store.create_run(\n\u001b[0m\u001b[1;32m    168\u001b[0m             \u001b[0mexperiment_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36mcreate_run\u001b[0;34m(self, experiment_id, user_id, start_time, tags, run_name)\u001b[0m\n\u001b[1;32m    207\u001b[0m             )\n\u001b[1;32m    208\u001b[0m         )\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresponse_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCreateRun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mRun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_proto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/store/tracking/rest_store.py\u001b[0m in \u001b[0;36m_call_endpoint\u001b[0;34m(self, api, json_body, endpoint)\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_METHOD_TO_INFO\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mresponse_proto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResponse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcall_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host_creds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_body\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_proto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     def search_experiments(\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mcall_endpoint\u001b[0;34m(host_creds, endpoint, method, json_body, response_proto, extra_headers)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhttp_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_rest_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m     \u001b[0mresponse_to_parse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[0mjs_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_to_parse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/mlflow/utils/rest_utils.py\u001b[0m in \u001b[0;36mverify_rest_response\u001b[0;34m(response, endpoint)\u001b[0m\n\u001b[1;32m    244\u001b[0m                 \u001b[0;34mf\"failed with error code {response.status_code} != 200\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             )\n\u001b[0;32m--> 246\u001b[0;31m             raise MlflowException(\n\u001b[0m\u001b[1;32m    247\u001b[0m                 \u001b[0;34mf\"{base_msg}. Response body: '{response.text}'\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m                 \u001b[0merror_code\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_error_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMlflowException\u001b[0m: API request to endpoint /api/2.0/mlflow/runs/create failed with error code 404 != 200. Response body: '<!DOCTYPE html>\n<html class=\"h-full\" lang=\"en-US\" dir=\"ltr\">\n  <head>\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Regular-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-RegularItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Medium-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-Semibold-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/euclid-square/EuclidSquare-MediumItalic-WebS.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-Text.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-TextItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-SemiBold.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <link rel=\"preload\" href=\"https://cdn.ngrok.com/static/fonts/ibm-plex-mono/IBMPlexMono-SemiBoldItalic.woff\" as=\"font\" type=\"font/woff\" crossorigin=\"anonymous\" />\n    <meta charset=\"utf-8\">\n    <meta name=\"author\" content=\"ngrok\">\n    <meta name=\"description\" content=\"ngrok is the fastest way to put anything on the internet with a single command.\">\n    <meta name=\"robots\" content=\"noindex, nofollow\">\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n    <link id=\"style\" rel=\"stylesheet\" href=\"https://cdn.ngrok.com/static/css/error.css\">\n    <noscript>Tunnel 5f5e-34-168-89-14.ngrok-free.app not found (ERR_NGROK_3200)</noscript>\n    <script id=\"script\" src=\"https://cdn.ngrok.com/static/js/error.js\" type=\"text/javascript\"></script>\n  </head>\n  <body class=\"h-full\" id=\"ngrok\">\n    <div id=\"root\" data-payload=\"eyJjZG5CYXNlIjoiaHR0cHM6Ly9jZG4ubmdyb2suY29tLyIsImNvZGUiOiIzMjAwIiwibWVzc2FnZSI6IlR1bm5lbCA1ZjVlLTM0LTE2OC04OS0xNC5uZ3Jvay1mcmVlLmFwcCBub3QgZm91bmQiLCJ0aXRsZSI6Ik5vdCBGb3VuZCJ9\"></div>\n  </body>\n</html>\n'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Define model registry path and create it if it doesn't exist\n",
    "#MODEL_REGISTRY = Path(\"./mlflow_experiments/\")\n",
    "#MODEL_REGISTRY.mkdir(exist_ok=True)\n",
    "\n",
    "# Set tracking URI\n",
    "#MLFLOW_TRACKING_URI = f\"file://{MODEL_REGISTRY.absolute()}\"\n",
    "#mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "\n",
    "# Authentication for ngrok (replace with your actual authtoken)\n",
    "!ngrok config add-authtoken 2mUbvf2qSsujKK9a6fKguc2yuCf_3k2z9A1WCHGGHDtAP4uqL\n",
    "\n",
    "# Set tracking URI\n",
    "#MLFLOW_TRACKING_URI = f\"{MODEL_REGISTRY.absolute()}\"\n",
    "mlflow.set_tracking_uri(\"https://5f5e-34-168-89-14.ngrok-free.app\")\n",
    "\n",
    "\n",
    "# Authentication for ngrok (replace with your actual authtoken)\n",
    "#ngrok.set_auth_token(\"2mUbvf2qSsujKK9a6fKguc2yuCf_3k2z9A1WCHGGHDtAP4uqL\")\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "\n",
    "NUM_EPOCHS = 2\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(modelv4.parameters(), lr=0.01)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Training loop\n",
    "    model_4_results = train(model=modelv4,\n",
    "                            train_dataloader=train_dataloader,\n",
    "                            test_dataloader=test_dataloader,\n",
    "                            loss=loss,\n",
    "                            optimizer=optimizer,\n",
    "                            epochs=NUM_EPOCHS)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.pytorch.log_model(modelv4, \"model2\")\n",
    "\n",
    "    mlflow.log_param(\"param1\", 5)\n",
    "    mlflow.log_metric(\"metric1\", 0.86)\n",
    "\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "# Start MLflow server in the background\n",
    "ngrok.kill()\n",
    "get_ipython().system_raw(\"mlflow ui --port 5000 &\")\n",
    "ngrok_tunnel = ngrok.connect(5000)\n",
    "print(f\"MLflow Tracking UI: {ngrok_tunnel.public_url}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local - technsorboard "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32bb1066bbd94135bea61afde1af552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0m/tjm8n82117bg4plwvf105j2h0000gn/T/ipykernel_10574/231928714.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature = torch.tensor(self.features[idx], dtype=torch.float32)\n",
      "/var/folders/0m/tjm8n82117bg4plwvf105j2h0000gn/T/ipykernel_10574/231928714.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Train Loss: 0.0333 | Test Loss: 0.5253 | Train Acc: 0.9875 | Test Acc: 0.9262\n",
      "Epoch: 2 | Train Loss: 0.0196 | Test Loss: 0.6175 | Train Acc: 0.9921 | Test Acc: 0.9264\n",
      "Epoch: 3 | Train Loss: 0.0177 | Test Loss: 0.7398 | Train Acc: 0.9925 | Test Acc: 0.9231\n",
      "Epoch: 4 | Train Loss: 0.0304 | Test Loss: 0.5798 | Train Acc: 0.9862 | Test Acc: 0.9227\n",
      "Epoch: 5 | Train Loss: 0.0234 | Test Loss: 0.8001 | Train Acc: 0.9917 | Test Acc: 0.9182\n",
      "Epoch: 6 | Train Loss: 0.0214 | Test Loss: 0.6476 | Train Acc: 0.9881 | Test Acc: 0.9245\n",
      "Epoch: 7 | Train Loss: 0.0208 | Test Loss: 0.7953 | Train Acc: 0.9929 | Test Acc: 0.9216\n",
      "Epoch: 8 | Train Loss: 0.0333 | Test Loss: 0.8455 | Train Acc: 0.9875 | Test Acc: 0.9245\n",
      "Epoch: 9 | Train Loss: 0.0741 | Test Loss: 0.6150 | Train Acc: 0.9758 | Test Acc: 0.9293\n",
      "Epoch: 10 | Train Loss: 0.0832 | Test Loss: 0.4331 | Train Acc: 0.9792 | Test Acc: 0.9130\n",
      "Epoch: 11 | Train Loss: 0.0456 | Test Loss: 0.4838 | Train Acc: 0.9875 | Test Acc: 0.9359\n",
      "Epoch: 12 | Train Loss: 0.0236 | Test Loss: 0.5302 | Train Acc: 0.9938 | Test Acc: 0.9280\n",
      "Epoch: 13 | Train Loss: 0.0202 | Test Loss: 0.5241 | Train Acc: 0.9929 | Test Acc: 0.9214\n",
      "Epoch: 14 | Train Loss: 0.0146 | Test Loss: 0.5967 | Train Acc: 0.9958 | Test Acc: 0.9260\n",
      "Epoch: 15 | Train Loss: 0.0180 | Test Loss: 0.6631 | Train Acc: 0.9933 | Test Acc: 0.9245\n",
      "Epoch: 16 | Train Loss: 0.0157 | Test Loss: 0.5384 | Train Acc: 0.9954 | Test Acc: 0.9276\n",
      "Epoch: 17 | Train Loss: 0.0134 | Test Loss: 0.5984 | Train Acc: 0.9954 | Test Acc: 0.9231\n",
      "Epoch: 18 | Train Loss: 0.0128 | Test Loss: 0.6392 | Train Acc: 0.9967 | Test Acc: 0.9229\n",
      "Epoch: 19 | Train Loss: 0.0164 | Test Loss: 0.6838 | Train Acc: 0.9933 | Test Acc: 0.9278\n",
      "Epoch: 20 | Train Loss: 0.0127 | Test Loss: 0.7345 | Train Acc: 0.9958 | Test Acc: 0.9266\n",
      "Epoch: 21 | Train Loss: 0.0116 | Test Loss: 0.7285 | Train Acc: 0.9975 | Test Acc: 0.9243\n",
      "Epoch: 22 | Train Loss: 0.0131 | Test Loss: 0.7210 | Train Acc: 0.9962 | Test Acc: 0.9278\n",
      "Epoch: 23 | Train Loss: 0.0153 | Test Loss: 0.7117 | Train Acc: 0.9938 | Test Acc: 0.9247\n",
      "Epoch: 24 | Train Loss: 0.0134 | Test Loss: 0.5788 | Train Acc: 0.9962 | Test Acc: 0.9326\n",
      "Epoch: 25 | Train Loss: 0.0307 | Test Loss: 0.7658 | Train Acc: 0.9904 | Test Acc: 0.9309\n",
      "Epoch: 26 | Train Loss: 0.0567 | Test Loss: 0.4980 | Train Acc: 0.9804 | Test Acc: 0.9278\n",
      "Epoch: 27 | Train Loss: 0.0323 | Test Loss: 0.4694 | Train Acc: 0.9908 | Test Acc: 0.9309\n",
      "Epoch: 28 | Train Loss: 0.0221 | Test Loss: 0.5353 | Train Acc: 0.9925 | Test Acc: 0.9212\n",
      "Epoch: 29 | Train Loss: 0.0210 | Test Loss: 0.5464 | Train Acc: 0.9938 | Test Acc: 0.9280\n",
      "Epoch: 30 | Train Loss: 0.0159 | Test Loss: 0.6540 | Train Acc: 0.9935 | Test Acc: 0.9278\n",
      "Epoch: 31 | Train Loss: 0.0118 | Test Loss: 0.5688 | Train Acc: 0.9971 | Test Acc: 0.9360\n",
      "Epoch: 32 | Train Loss: 0.0090 | Test Loss: 0.7208 | Train Acc: 0.9967 | Test Acc: 0.9235\n",
      "Epoch: 33 | Train Loss: 0.0088 | Test Loss: 0.7029 | Train Acc: 0.9975 | Test Acc: 0.9280\n",
      "Epoch: 34 | Train Loss: 0.0093 | Test Loss: 0.8009 | Train Acc: 0.9975 | Test Acc: 0.9233\n",
      "Epoch: 35 | Train Loss: 0.0086 | Test Loss: 0.7127 | Train Acc: 0.9967 | Test Acc: 0.9266\n",
      "Epoch: 36 | Train Loss: 0.0084 | Test Loss: 0.7905 | Train Acc: 0.9971 | Test Acc: 0.9278\n",
      "Epoch: 37 | Train Loss: 0.0108 | Test Loss: 0.7304 | Train Acc: 0.9971 | Test Acc: 0.9295\n",
      "Epoch: 38 | Train Loss: 0.0103 | Test Loss: 0.7722 | Train Acc: 0.9950 | Test Acc: 0.9309\n",
      "Epoch: 39 | Train Loss: 0.0122 | Test Loss: 0.7271 | Train Acc: 0.9962 | Test Acc: 0.9266\n",
      "Epoch: 40 | Train Loss: 0.0111 | Test Loss: 0.7542 | Train Acc: 0.9954 | Test Acc: 0.9293\n",
      "Total time: 1.8433 seconds\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.17.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorboard\n",
    "\n",
    "writer = SummaryWriter('./runs/run_7')\n",
    "\n",
    "# Training loop \n",
    "NUM_EPOCHS = 40\n",
    "\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = Adam(modelv4.parameters(), lr=0.01)\n",
    "\n",
    "start_time = timer()\n",
    "\n",
    "model_4_results = train(model=modelv4,\n",
    "                        train_dataloader=train_dataloader,\n",
    "                        test_dataloader=test_dataloader,\n",
    "                        loss=loss,\n",
    "                        optimizer=optimizer,\n",
    "                        epochs=NUM_EPOCHS)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "end_time = timer()\n",
    "print(f\"Total time: {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "writer.flush()\n",
    "\n",
    "\n",
    "!tensorboard --logdir=./runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optune Hyperparamter optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/timesynth-0.2.4-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcxde_common-1.4.1-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/symengine-0.11.0-py3.12-macosx-11.0-arm64.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /opt/anaconda3/lib/python3.12/site-packages/jitcdde-1.4.0-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation.. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install jupyterlab jupyterlab-optuna --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out which hyperparamter are hte most important ->can't optimise all since curvse of dimentionality \n",
    "# then optimise those paramters\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMQAmxY3/V/LKrFAH2An7Z0",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
